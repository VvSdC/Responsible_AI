## Fairness and Bias

Fairness and bias are important to make sure AI systems do not treat people unfairly or increase discrimination. It is important to design and use algorithms that give fair results to everyone, no matter their background or personal details.

- Fairness and bias mean making sure AI systems are built and used in a fair way.
- This includes removing unfair results that can happen because of biased data or unfair algorithms.

---

## ⚠️ Bias in AI Systems

Bias in AI happens when a system unfairly helps or harms certain groups. This often comes from problems in the data, the algorithms, or human choices during development.

### Common Sources of Bias

- **Training Data Bias:** AI learns from the data it is given. If the data has stereotypes or does not include some groups well, the AI will learn those problems too.
- **Algorithmic Bias:** The AI model can make hidden unfair patterns stronger if they exist in the data.
- **Human Bias:** Developers and reviewers bring their own beliefs and assumptions, which can add bias during labeling or decision-making.
- **Cognitive Limitations:** People can miss hidden bias if they do not look at the data or model carefully enough.

### Real-World Effects of Bias

- In **hiring systems**, AI might favor resumes from certain names, schools, or regions more than others.
- In **financial services**, models that approve loans might unfairly reject women or people from minority groups.
- **Representation bias** happens when a group is missing or badly shown in the training data.
- **Aggregation bias** happens when a model wrongly treats different groups the same, even when there are important differences.
- **Human-in-the-loop bias** happens when people override correct model results based on personal beliefs — if the AI learns from these overrides, the bias can get worse over time.

---
